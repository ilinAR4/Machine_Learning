"""
–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –æ–±—É—á–µ–Ω–∏–µ ‚Üí –æ—Ü–µ–Ω–∫–∞ ‚Üí –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
"""

import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    precision_score, recall_score, f1_score, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import zipfile
import io

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

st.title("üèãÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π")
st.markdown("---")


# ==================== –§–£–ù–ö–¶–ò–ò –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ====================

@st.cache_data
def load_demo_data(num_samples=5000):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    st.info("üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç (5000 –∑–∞–ø–∏—Å–µ–π)...")
    
    exercises = ['e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8']
    data = []
    
    for i in range(num_samples):
        exercise = np.random.choice(exercises)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è IMU –¥–∞—Ç—á–∏–∫–æ–≤
        accel = np.random.normal([0, -9.8, 0], [2, 1.5, 2])
        gyro = np.random.normal([0, 0, 0], [0.5, 0.5, 0.5])
        mag = np.random.normal([0.6, 0.45, -0.08], [0.02, 0.02, 0.02])
        
        data.append({
            'Session': f's{np.random.randint(1, 6)}',
            'Exercise': exercise,
            'User': f'u{np.random.randint(1, 6)}',
            'A_x': accel[0],
            'A_y': accel[1],
            'A_z': accel[2],
            'G_x': gyro[0],
            'G_y': gyro[1],
            'G_z': gyro[2],
            'M_x': mag[0],
            'M_y': mag[1],
            'M_z': mag[2],
            'Workout': exercise
        })
    
    return pd.DataFrame(data)


@st.cache_data
def load_uci_physical_therapy():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Physical Therapy Exercises"""
    st.warning("‚ö†Ô∏è –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ API")
    st.info("""
    üì• –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤—Ä—É—á–Ω—É—é:
    
    1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞: https://archive.ics.uci.edu/dataset/730/physical+therapy+exercises
    2. –°–∫–∞—á–∞–π—Ç–µ ZIP –∞—Ä—Ö–∏–≤ (45.7 MB)
    3. –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤" –≤—ã—à–µ
    4. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    """)
    return None


@st.cache_data
def load_from_zip(uploaded_zip, sample_rate=1):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ ZIP –∞—Ä—Ö–∏–≤–∞ —Å TXT —Ñ–∞–π–ª–∞–º–∏ Physical Therapy
    sample_rate: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è (1=–≤—Å–µ –¥–∞–Ω–Ω—ã–µ, 2=–∫–∞–∂–¥–∞—è –≤—Ç–æ—Ä–∞—è –∑–∞–ø–∏—Å—å, –∏ —Ç.–¥.)
    """
    
    try:
        with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:
            file_list = zip_ref.namelist()
            txt_files = [f for f in file_list if f.endswith('.txt') and not f.startswith('__MACOSX')]
            
            st.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(txt_files)} TXT —Ñ–∞–π–ª–æ–≤ –≤ –∞—Ä—Ö–∏–≤–µ")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è DataFrame –ø–æ —á–∞—Å—Ç—è–º
            dataframes = []
            chunk_data = []
            chunk_size = 10000  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 10000 –∑–∞–ø–∏—Å–µ–π
            
            files_processed = 0
            total_records = 0
            errors = []
            
            for idx, txt_file in enumerate(txt_files):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—É—Ç–∏
                    parts = txt_file.replace('\\', '/').split('/')
                    
                    session = None
                    exercise = None  
                    user = None
                    
                    for part in parts:
                        if part.startswith('s') and len(part) <= 3:
                            session = part
                        elif part.startswith('e') and len(part) <= 3:
                            exercise = part
                        elif part.startswith('u') and len(part) <= 3:
                            user = part
                    
                    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                    with zip_ref.open(txt_file) as f:
                        content = f.read()
                        
                        try:
                            text = content.decode('utf-8')
                        except:
                            try:
                                text = content.decode('latin-1')
                            except:
                                text = content.decode('cp1252', errors='ignore')
                        
                        lines = text.strip().split('\n')
                        
                        for line_idx, line in enumerate(lines):
                            # –ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                            if line_idx % sample_rate != 0:
                                continue
                            
                            line = line.strip()
                            
                            if not line or 'time index' in line.lower() or line.startswith('#'):
                                continue
                            
                            values = line.split(';')
                            values = [v.strip() for v in values if v.strip()]
                            
                            if len(values) >= 10:
                                try:
                                    row = {
                                        'Session': session if session else 'unknown',
                                        'Exercise': exercise if exercise else 'unknown',
                                        'User': user if user else 'unknown',
                                        'A_x': float(values[1]),
                                        'A_y': float(values[2]),
                                        'A_z': float(values[3]),
                                        'G_x': float(values[4]),
                                        'G_y': float(values[5]),
                                        'G_z': float(values[6]),
                                        'M_x': float(values[7]),
                                        'M_y': float(values[8]),
                                        'M_z': float(values[9]),
                                        'Workout': exercise if exercise else 'unknown'
                                    }
                                    chunk_data.append(row)
                                    total_records += 1
                                    
                                    # –ö–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏–ª–∏ chunk_size –∑–∞–ø–∏—Å–µ–π, —Å–æ–∑–¥–∞–µ–º DataFrame
                                    if len(chunk_data) >= chunk_size:
                                        dataframes.append(pd.DataFrame(chunk_data))
                                        chunk_data = []
                                        
                                except (ValueError, IndexError):
                                    continue
                        
                        files_processed += 1
                
                except Exception as e:
                    errors.append(f"{txt_file}: {str(e)[:50]}")
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                if idx % 10 == 0 or idx == len(txt_files) - 1:
                    progress = (idx + 1) / len(txt_files)
                    progress_bar.progress(progress)
                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx + 1}/{len(txt_files)} | –ó–∞–ø–∏—Å–µ–π: {total_records:,}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π chunk
            if chunk_data:
                dataframes.append(pd.DataFrame(chunk_data))
            
            progress_bar.empty()
            status_text.empty()
            
            if dataframes:
                st.info("üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
                df = pd.concat(dataframes, ignore_index=True)
                
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ {files_processed} —Ñ–∞–π–ª–æ–≤")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                st.info(f"""
                üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏:
                - –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {files_processed}
                - –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df):,}
                - –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–π: {df['Exercise'].nunique()}
                - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {df['User'].nunique()}
                - –°–µ—Å—Å–∏–π: {df['Session'].nunique()}
                - –ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ: –∫–∞–∂–¥–∞—è {sample_rate}-—è –∑–∞–ø–∏—Å—å
                """)
                
                return df
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ")
                return None
            
    except MemoryError:
        st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏!")
        st.warning("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (sample_rate > 1)")
        return None
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None


# ==================== –§–£–ù–ö–¶–ò–ò –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò ====================

def calculate_derived_features(data):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    # –í–µ–ª–∏—á–∏–Ω–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
    data['accel_magnitude'] = np.sqrt(
        data['accel_x']**2 + data['accel_y']**2 + data['accel_z']**2
    )
    
    # –í–µ–ª–∏—á–∏–Ω–∞ —É–≥–ª–æ–≤–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
    data['gyro_magnitude'] = np.sqrt(
        data['gyro_x']**2 + data['gyro_y']**2 + data['gyro_z']**2
    )
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    for col in ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']:
        data[f'{col}_diff'] = data[col].diff().fillna(0)
    
    return data


def extract_window_features(segment, sensor_columns):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞"""
    features = {}
    
    for column in sensor_columns:
        sensor_data = segment[column].values
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features[f'{column}_mean'] = np.mean(sensor_data)
        features[f'{column}_std'] = np.std(sensor_data)
        features[f'{column}_max'] = np.max(sensor_data)
        features[f'{column}_min'] = np.min(sensor_data)
        features[f'{column}_median'] = np.median(sensor_data)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        features[f'{column}_skew'] = stats.skew(sensor_data)
        features[f'{column}_kurtosis'] = stats.kurtosis(sensor_data)
        
        # –≠–Ω–µ—Ä–≥–∏—è
        features[f'{column}_energy'] = np.sum(sensor_data**2) / len(sensor_data)
        
        # –î–∏–∞–ø–∞–∑–æ–Ω
        features[f'{column}_range'] = np.max(sensor_data) - np.min(sensor_data)
    
    return features


@st.cache_data
def preprocess_data(data, window_size=50, overlap=0.5):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
    data = data.rename(columns={
        'A_x': 'accel_x', 'A_y': 'accel_y', 'A_z': 'accel_z',
        'G_x': 'gyro_x', 'G_y': 'gyro_y', 'G_z': 'gyro_z',
        'Workout': 'exercise_type'
    })
    
    # –°–æ–∑–¥–∞–Ω–∏–µ timestamp
    data['timestamp'] = data.index
    data = data.sort_values('timestamp').reset_index(drop=True)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    data = calculate_derived_features(data)
    
    # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    step_size = int(window_size * (1 - overlap))
    segments = []
    labels = []
    
    sensor_columns = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z',
                      'accel_magnitude', 'gyro_magnitude']
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_segments = (len(data) - window_size) // step_size + 1
    
    for idx, start_idx in enumerate(range(0, len(data) - window_size + 1, step_size)):
        end_idx = start_idx + window_size
        segment = data.iloc[start_idx:end_idx]
        
        features = extract_window_features(segment, sensor_columns)
        segments.append(features)
        
        # –ú–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–µ—Ç–∫–∏
        label_counts = segment['exercise_type'].value_counts()
        if not label_counts.empty:
            labels.append(label_counts.index[0])
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if idx % 10 == 0:
            progress = (idx + 1) / total_segments
            progress_bar.progress(min(progress, 1.0))
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {idx + 1} / {total_segments}")
    
    progress_bar.empty()
    status_text.empty()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    feature_df = pd.DataFrame(segments)
    feature_df['exercise_type'] = labels
    
    return feature_df
# ==================== –§–£–ù–ö–¶–ò–ò –û–ë–£–ß–ï–ù–ò–Ø ====================

def train_model(model_type, X_train, X_test, y_train, y_test):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
    
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),
        'SVM': SVC(kernel='rbf', probability=True, random_state=42),
        'XGBoost': XGBClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1, eval_metric='mlogloss'),
        'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),
        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, n_jobs=-1)
    }
    
    model = models[model_type]
    
    # –û–±—É—á–µ–Ω–∏–µ
    model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1)
    
    metrics = {
        'model': model,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'confusion_matrix': confusion_matrix(y_test, y_pred),
        'classification_report': classification_report(y_test, y_pred, output_dict=True, zero_division=0)
    }
    
    return metrics


def plot_confusion_matrix(cm, classes):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"""
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)
    ax.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', fontsize=16, fontweight='bold')
    ax.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏', fontsize=12)
    ax.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    return fig


def plot_feature_importance(model, feature_names, top_n=20):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    if hasattr(model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False).head(top_n)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.barplot(data=importance_df, y='feature', x='importance', palette='viridis', ax=ax)
        ax.set_title(f'–¢–æ–ø-{top_n} –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16, fontweight='bold')
        ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å', fontsize=12)
        ax.set_ylabel('–ü—Ä–∏–∑–Ω–∞–∫', fontsize=12)
        plt.tight_layout()
        return fig
    return None


def plot_class_accuracy(y_test, y_pred, classes):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º"""
    class_accuracy = []
    for class_name in classes:
        class_mask = y_test == class_name
        if np.sum(class_mask) > 0:
            acc = np.mean(y_pred[class_mask] == class_name)
            class_accuracy.append(acc)
        else:
            class_accuracy.append(0)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars = ax.bar(classes, class_accuracy, color='skyblue', edgecolor='navy')
    ax.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π', fontsize=16, fontweight='bold')
    ax.set_xlabel('–ö–ª–∞—Å—Å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è', fontsize=12)
    ax.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    ax.set_ylim([0, 1.1])
    plt.xticks(rotation=45, ha='right')
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, acc in zip(bars, class_accuracy):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{acc:.2f}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    return fig


# ==================== –ò–ù–¢–ï–†–§–ï–ô–° ====================

# –°–µ–∫—Ü–∏—è 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
st.header("üìÅ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

data_source = st.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:",
    [
        "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤",
        "üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª",
        "üß™ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ",
    ],
    horizontal=False,
    index=0
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = None

if data_source == "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤":
    uploaded_zip = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤ —Å TXT —Ñ–∞–π–ª–∞–º–∏", type=['zip'])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è
    sample_rate = st.slider(
        "–ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)",
        min_value=1, max_value=10, value=2,
        help="1 = –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, 2 = –∫–∞–∂–¥–∞—è –≤—Ç–æ—Ä–∞—è –∑–∞–ø–∏—Å—å, 10 = –∫–∞–∂–¥–∞—è –¥–µ—Å—è—Ç–∞—è"
    )
    
    if uploaded_zip is not None:
        if st.button("üîì –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å", type="primary"):
            data = load_from_zip(uploaded_zip, sample_rate)
            if data is not None:
                st.session_state['raw_data'] = data

elif data_source == "üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª":
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º", type=['csv'])
    if uploaded_file is not None:
        try:
            data = pd.read_csv(uploaded_file)
            st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
            st.session_state['raw_data'] = data
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")

elif data_source == "üß™ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ":
    if st.button("üé≤ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ", type="primary"):
        data = load_demo_data()
        st.session_state['raw_data'] = data

# –í–°–ï–ì–î–ê –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session_state
if 'raw_data' in st.session_state:
    data = st.session_state['raw_data']

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
if data is not None:
    st.subheader("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", f"{len(data):,}")
    col2.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", len(data.columns) - 1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –º–µ—Ç–∫–∞–º–∏
    label_col = None
    for col in ['Workout', 'Exercise', 'exercise_type', 'label', 'class']:
        if col in data.columns:
            label_col = col
            break
    
    if label_col:
        col3.metric("–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–π", data[label_col].nunique())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—É–±—ä–µ–∫—Ç–∞—Ö
    subject_col = None
    for col in ['Subject', 'User', 'subject', 'user']:
        if col in data.columns:
            subject_col = col
            break
    
    if subject_col:
        col4.metric("–°—É–±—ä–µ–∫—Ç–æ–≤", data[subject_col].nunique())
    
    with st.expander("üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
        st.dataframe(data.head(100), use_container_width=True)
    
    if label_col:
        with st.expander("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π"):
            workout_counts = data[label_col].value_counts()
            fig, ax = plt.subplots(figsize=(12, 6))
            workout_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='navy')
            ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ', fontsize=14, fontweight='bold')
            ax.set_xlabel('–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ')
            ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    st.markdown("---")
    
    # –°–µ–∫—Ü–∏—è 2: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    st.header("üîÑ 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    col1, col2 = st.columns(2)
    with col1:
        window_size = st.slider("–†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π)", 20, 100, 50, 5)
    with col2:
        overlap = st.slider("–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –æ–∫–æ–Ω", 0.0, 0.9, 0.5, 0.1)
    
    if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
        with st.spinner("‚è≥ –ò–¥—ë—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            processed_data = preprocess_data(data, window_size, overlap)
            st.session_state['processed_data'] = processed_data
            st.success(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(processed_data)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤.")
    
    # –°–µ–∫—Ü–∏—è 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    if 'processed_data' in st.session_state:
        st.markdown("---")
        st.header("ü§ñ 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
        
        processed_data = st.session_state['processed_data']
        
        col1, col2 = st.columns(2)
        with col1:
            model_type = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
                ['Random Forest', 'Logistic Regression', 'SVM', 'XGBoost', 'Decision Tree', 'K-Nearest Neighbors']
            )
        
        with col2:
            test_size = st.slider("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏", 0.1, 0.4, 0.2, 0.05)
        
        if st.button("üéØ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
            with st.spinner(f"‚è≥ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_type}..."):
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                X = processed_data.drop(columns=['exercise_type'])
                y = processed_data['exercise_type']
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=test_size, random_state=42, stratify=y
                )
                
                # –û–±—É—á–µ–Ω–∏–µ
                metrics = train_model(model_type, X_train, X_test, y_train, y_test)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
                st.session_state['metrics'] = metrics
                st.session_state['X_test'] = X_test
                st.session_state['y_test'] = y_test
                st.session_state['scaler'] = scaler
                st.session_state['feature_names'] = X.columns.tolist()
                st.session_state['model_type'] = model_type
                
                st.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_type} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
        
        # –°–µ–∫—Ü–∏—è 4: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if 'metrics' in st.session_state:
            st.markdown("---")
            st.header("üìä 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
            
            metrics = st.session_state['metrics']
            model_type = st.session_state['model_type']
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            st.subheader(f"üìà –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏: {model_type}")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Accuracy", f"{metrics['accuracy']:.4f}")
            col2.metric("Precision", f"{metrics['precision']:.4f}")
            col3.metric("Recall", f"{metrics['recall']:.4f}")
            col4.metric("F1-Score", f"{metrics['f1_score']:.4f}")
            
            col1, col2 = st.columns(2)
            col1.metric("CV Mean", f"{metrics['cv_mean']:.4f}")
            col2.metric("CV Std", f"{metrics['cv_std']:.4f}")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            
            tab1, tab2, tab3, tab4 = st.tabs(["–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", "–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", "–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º", "–û—Ç—á—ë—Ç"])
            
            with tab1:
                classes = np.unique(st.session_state['y_test'])
                fig_cm = plot_confusion_matrix(metrics['confusion_matrix'], classes)
                st.pyplot(fig_cm)
                plt.close()
            
            with tab2:
                fig_fi = plot_feature_importance(metrics['model'], st.session_state['feature_names'])
                if fig_fi:
                    st.pyplot(fig_fi)
                    plt.close()
                else:
                    st.info("–î–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            with tab3:
                fig_ca = plot_class_accuracy(st.session_state['y_test'], metrics['y_pred'], classes)
                st.pyplot(fig_ca)
                plt.close()
            
            with tab4:
                st.text("–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
                report_df = pd.DataFrame(metrics['classification_report']).transpose()
                st.dataframe(report_df, use_container_width=True)
            
            # –°–µ–∫—Ü–∏—è 5: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            st.markdown("---")
            st.header("üîÆ 5. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
            st.info("üí° –í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞—Ç—á–∏–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–∏–ø–∞ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è")
            
            with st.form("prediction_form"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**–ê–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä (–º/—Å¬≤)**")
                    a_x = st.number_input("A_x", value=0.0, format="%.3f")
                    a_y = st.number_input("A_y", value=-9.8, format="%.3f")
                    a_z = st.number_input("A_z", value=0.0, format="%.3f")
                
                with col2:
                    st.markdown("**–ì–∏—Ä–æ—Å–∫–æ–ø (—Ä–∞–¥/—Å)**")
                    g_x = st.number_input("G_x", value=0.0, format="%.3f")
                    g_y = st.number_input("G_y", value=0.0, format="%.3f")
                    g_z = st.number_input("G_z", value=0.0, format="%.3f")
                
                with col3:
                    st.markdown("**–ú–∞–≥–Ω–∏—Ç–æ–º–µ—Ç—Ä**")
                    m_x = st.number_input("M_x", value=0.6, format="%.3f")
                    m_y = st.number_input("M_y", value=0.45, format="%.3f")
                    m_z = st.number_input("M_z", value=-0.08, format="%.3f")
                
                submit = st.form_submit_button("üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å", type="primary")
                
                if submit:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    accel_magnitude = np.sqrt(a_x**2 + a_y**2 + a_z**2)
                    gyro_magnitude = np.sqrt(g_x**2 + g_y**2 + g_z**2)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ–∫–Ω–∞)
                    window_data = pd.DataFrame([{
                        'accel_x': a_x, 'accel_y': a_y, 'accel_z': a_z,
                        'gyro_x': g_x, 'gyro_y': g_y, 'gyro_z': g_z,
                        'accel_magnitude': accel_magnitude,
                        'gyro_magnitude': gyro_magnitude
                    }] * 50)  # –ü–æ–≤—Ç–æ—Ä—è–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–Ω–∞
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z',
                                   'accel_magnitude', 'gyro_magnitude']
                    features = extract_window_features(window_data, sensor_cols)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º —Å—Ç–æ–ª–±—Ü–æ–≤
                    feature_df = pd.DataFrame([features])
                    feature_df = feature_df[st.session_state['feature_names']]
                    
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                    X_pred = st.session_state['scaler'].transform(feature_df)
                    
                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    prediction = metrics['model'].predict(X_pred)[0]
                    
                    if hasattr(metrics['model'], 'predict_proba'):
                        proba = metrics['model'].predict_proba(X_pred)[0]
                        confidence = np.max(proba)
                        
                        st.success(f"### üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ: **{prediction}**")
                        st.info(f"### üíØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: **{confidence:.2%}**")
                        
                        st.markdown("#### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º:")
                        proba_df = pd.DataFrame({
                            '–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ': metrics['model'].classes_,
                            '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': proba
                        }).sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False)
                        
                        st.dataframe(proba_df, use_container_width=True)
                        
                        # –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.barh(proba_df['–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ'], proba_df['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'], color='steelblue')
                        ax.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
                        ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
                        ax.set_xlim([0, 1])
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close()
                    else:
                        st.success(f"### üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ: **{prediction}**")

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")