"""
–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –æ–±—É—á–µ–Ω–∏–µ ‚Üí –æ—Ü–µ–Ω–∫–∞ ‚Üí –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
"""

import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    precision_score, recall_score, f1_score, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import zipfile
import io

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

st.title("üèãÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π")
st.markdown("---")


# ==================== –§–£–ù–ö–¶–ò–ò –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ====================

@st.cache_data
def load_demo_data(num_samples=5000):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    st.info("üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç (5000 –∑–∞–ø–∏—Å–µ–π)...")
    
    exercises = ['e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8']
    data = []
    
    for i in range(num_samples):
        exercise = np.random.choice(exercises)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è IMU –¥–∞—Ç—á–∏–∫–æ–≤
        accel = np.random.normal([0, -9.8, 0], [2, 1.5, 2])
        gyro = np.random.normal([0, 0, 0], [0.5, 0.5, 0.5])
        mag = np.random.normal([0.6, 0.45, -0.08], [0.02, 0.02, 0.02])
        
        data.append({
            'Session': f's{np.random.randint(1, 6)}',
            'Exercise': exercise,
            'User': f'u{np.random.randint(1, 6)}',
            'A_x': accel[0],
            'A_y': accel[1],
            'A_z': accel[2],
            'G_x': gyro[0],
            'G_y': gyro[1],
            'G_z': gyro[2],
            'M_x': mag[0],
            'M_y': mag[1],
            'M_z': mag[2],
            'Workout': exercise
        })
    
    return pd.DataFrame(data)


@st.cache_data
def load_uci_physical_therapy():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Physical Therapy Exercises"""
    st.warning("‚ö†Ô∏è –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ API")
    st.info("""
    üì• –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤—Ä—É—á–Ω—É—é:
    
    1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞: https://archive.ics.uci.edu/dataset/730/physical+therapy+exercises
    2. –°–∫–∞—á–∞–π—Ç–µ ZIP –∞—Ä—Ö–∏–≤ (45.7 MB)
    3. –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤" –≤—ã—à–µ
    4. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    """)
    return None


@st.cache_data
def load_from_zip(uploaded_zip, sample_rate=1):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ ZIP –∞—Ä—Ö–∏–≤–∞ —Å TXT —Ñ–∞–π–ª–∞–º–∏ Physical Therapy
    sample_rate: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è (1=–≤—Å–µ –¥–∞–Ω–Ω—ã–µ, 2=–∫–∞–∂–¥–∞—è –≤—Ç–æ—Ä–∞—è –∑–∞–ø–∏—Å—å, –∏ —Ç.–¥.)
    """
    
    try:
        with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:
            file_list = zip_ref.namelist()
            txt_files = [f for f in file_list if f.endswith('.txt') and not f.startswith('__MACOSX')]
            
            st.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(txt_files)} TXT —Ñ–∞–π–ª–æ–≤ –≤ –∞—Ä—Ö–∏–≤–µ")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è DataFrame –ø–æ —á–∞—Å—Ç—è–º
            dataframes = []
            chunk_data = []
            chunk_size = 10000  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 10000 –∑–∞–ø–∏—Å–µ–π
            
            files_processed = 0
            total_records = 0
            errors = []
            
            for idx, txt_file in enumerate(txt_files):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—É—Ç–∏
                    parts = txt_file.replace('\\', '/').split('/')
                    
                    session = None
                    exercise = None  
                    user = None
                    
                    for part in parts:
                        if part.startswith('s') and len(part) <= 3:
                            session = part
                        elif part.startswith('e') and len(part) <= 3:
                            exercise = part
                        elif part.startswith('u') and len(part) <= 3:
                            user = part
                    
                    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                    with zip_ref.open(txt_file) as f:
                        content = f.read()
                        
                        try:
                            text = content.decode('utf-8')
                        except:
                            try:
                                text = content.decode('latin-1')
                            except:
                                text = content.decode('cp1252', errors='ignore')
                        
                        lines = text.strip().split('\n')
                        
                        for line_idx, line in enumerate(lines):
                            # –ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                            if line_idx % sample_rate != 0:
                                continue
                            
                            line = line.strip()
                            
                            if not line or 'time index' in line.lower() or line.startswith('#'):
                                continue
                            
                            values = line.split(';')
                            values = [v.strip() for v in values if v.strip()]
                            
                            if len(values) >= 10:
                                try:
                                    row = {
                                        'Session': session if session else 'unknown',
                                        'Exercise': exercise if exercise else 'unknown',
                                        'User': user if user else 'unknown',
                                        'A_x': float(values[1]),
                                        'A_y': float(values[2]),
                                        'A_z': float(values[3]),
                                        'G_x': float(values[4]),
                                        'G_y': float(values[5]),
                                        'G_z': float(values[6]),
                                        'M_x': float(values[7]),
                                        'M_y': float(values[8]),
                                        'M_z': float(values[9]),
                                        'Workout': exercise if exercise else 'unknown'
                                    }
                                    chunk_data.append(row)
                                    total_records += 1
                                    
                                    # –ö–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏–ª–∏ chunk_size –∑–∞–ø–∏—Å–µ–π, —Å–æ–∑–¥–∞–µ–º DataFrame
                                    if len(chunk_data) >= chunk_size:
                                        dataframes.append(pd.DataFrame(chunk_data))
                                        chunk_data = []
                                        
                                except (ValueError, IndexError):
                                    continue
                        
                        files_processed += 1
                
                except Exception as e:
                    errors.append(f"{txt_file}: {str(e)[:50]}")
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                if idx % 10 == 0 or idx == len(txt_files) - 1:
                    progress = (idx + 1) / len(txt_files)
                    progress_bar.progress(progress)
                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx + 1}/{len(txt_files)} | –ó–∞–ø–∏—Å–µ–π: {total_records:,}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π chunk
            if chunk_data:
                dataframes.append(pd.DataFrame(chunk_data))
            
            progress_bar.empty()
            status_text.empty()
            
            if dataframes:
                st.info("üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
                df = pd.concat(dataframes, ignore_index=True)
                
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ {files_processed} —Ñ–∞–π–ª–æ–≤")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                st.info(f"""
                üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏:
                - –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {files_processed}
                - –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df):,}
                - –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–π: {df['Exercise'].nunique()}
                - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {df['User'].nunique()}
                - –°–µ—Å—Å–∏–π: {df['Session'].nunique()}
                - –ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ: –∫–∞–∂–¥–∞—è {sample_rate}-—è –∑–∞–ø–∏—Å—å
                """)
                
                return df
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ")
                return None
            
    except MemoryError:
        st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏!")
        st.warning("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (sample_rate > 1)")
        return None
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None


# ==================== –§–£–ù–ö–¶–ò–ò –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò ====================

def calculate_derived_features(data):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    # –í–µ–ª–∏—á–∏–Ω–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
    data['accel_magnitude'] = np.sqrt(
        data['accel_x']**2 + data['accel_y']**2 + data['accel_z']**2
    )
    
    # –í–µ–ª–∏—á–∏–Ω–∞ —É–≥–ª–æ–≤–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
    data['gyro_magnitude'] = np.sqrt(
        data['gyro_x']**2 + data['gyro_y']**2 + data['gyro_z']**2
    )
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    for col in ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']:
        data[f'{col}_diff'] = data[col].diff().fillna(0)
    
    return data


def extract_window_features(segment, sensor_columns):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞"""
    features = {}
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_translation = {
        'mean': '—Å—Ä–µ–¥–Ω–µ–µ',
        'std': '—Å—Ç–∞–Ω–¥_–æ—Ç–∫–ª',
        'max': '–º–∞–∫—Å–∏–º—É–º',
        'min': '–º–∏–Ω–∏–º—É–º',
        'median': '–º–µ–¥–∏–∞–Ω–∞',
        'skew': '–∞—Å–∏–º–º–µ—Ç—Ä–∏—è',
        'kurtosis': '—ç–∫—Å—Ü–µ—Å—Å',
        'energy': '—ç–Ω–µ—Ä–≥–∏—è',
        'range': '–¥–∏–∞–ø–∞–∑–æ–Ω'
    }
    
    sensor_translation = {
        'accel_x': '–∞–∫—Å_x',
        'accel_y': '–∞–∫—Å_y',
        'accel_z': '–∞–∫—Å_z',
        'gyro_x': '–≥–∏—Ä_x',
        'gyro_y': '–≥–∏—Ä_y',
        'gyro_z': '–≥–∏—Ä_z',
        'accel_magnitude': '–∞–∫—Å_–º–∞–≥–Ω–∏—Ç—É–¥–∞',
        'gyro_magnitude': '–≥–∏—Ä_–º–∞–≥–Ω–∏—Ç—É–¥–∞'
    }
    
    for column in sensor_columns:
        sensor_data = segment[column].values
        
        # –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–∞—Ç—á–∏–∫–∞
        sensor_name_ru = sensor_translation.get(column, column)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
        if len(sensor_data) == 0:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            for feat_name, feat_name_ru in feature_translation.items():
                features[f'{sensor_name_ru}_{feat_name_ru}'] = 0.0
            continue
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∑–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0)
        features[f'{sensor_name_ru}_—Å—Ä–µ–¥–Ω–µ–µ'] = np.nan_to_num(np.mean(sensor_data), nan=0.0)
        features[f'{sensor_name_ru}_—Å—Ç–∞–Ω–¥_–æ—Ç–∫–ª'] = np.nan_to_num(np.std(sensor_data), nan=0.0)
        features[f'{sensor_name_ru}_–º–∞–∫—Å–∏–º—É–º'] = np.nan_to_num(np.max(sensor_data), nan=0.0)
        features[f'{sensor_name_ru}_–º–∏–Ω–∏–º—É–º'] = np.nan_to_num(np.min(sensor_data), nan=0.0)
        features[f'{sensor_name_ru}_–º–µ–¥–∏–∞–Ω–∞'] = np.nan_to_num(np.median(sensor_data), nan=0.0)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–æ–±—Ä–∞–±–æ—Ç–∫–∞ NaN)
        skew_val = stats.skew(sensor_data)
        features[f'{sensor_name_ru}_–∞—Å–∏–º–º–µ—Ç—Ä–∏—è'] = np.nan_to_num(skew_val, nan=0.0)
        
        kurt_val = stats.kurtosis(sensor_data)
        features[f'{sensor_name_ru}_—ç–∫—Å—Ü–µ—Å—Å'] = np.nan_to_num(kurt_val, nan=0.0)
        
        # –≠–Ω–µ—Ä–≥–∏—è
        energy_val = np.sum(sensor_data**2) / len(sensor_data) if len(sensor_data) > 0 else 0.0
        features[f'{sensor_name_ru}_—ç–Ω–µ—Ä–≥–∏—è'] = np.nan_to_num(energy_val, nan=0.0)
        
        # –î–∏–∞–ø–∞–∑–æ–Ω
        range_val = np.max(sensor_data) - np.min(sensor_data)
        features[f'{sensor_name_ru}_–¥–∏–∞–ø–∞–∑–æ–Ω'] = np.nan_to_num(range_val, nan=0.0)
    
    return features


@st.cache_data
def preprocess_data(data, window_size=50, overlap=0.5):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
    data = data.rename(columns={
        'A_x': 'accel_x', 'A_y': 'accel_y', 'A_z': 'accel_z',
        'G_x': 'gyro_x', 'G_y': 'gyro_y', 'G_z': 'gyro_z',
        'Workout': 'exercise_type'
    })
    
    # –°–æ–∑–¥–∞–Ω–∏–µ timestamp
    data['timestamp'] = data.index
    data = data.sort_values('timestamp').reset_index(drop=True)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    data = calculate_derived_features(data)
    
    # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    step_size = int(window_size * (1 - overlap))
    segments = []
    labels = []
    
    sensor_columns = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z',
                      'accel_magnitude', 'gyro_magnitude']
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_segments = (len(data) - window_size) // step_size + 1
    
    for idx, start_idx in enumerate(range(0, len(data) - window_size + 1, step_size)):
        end_idx = start_idx + window_size
        segment = data.iloc[start_idx:end_idx]
        
        features = extract_window_features(segment, sensor_columns)
        segments.append(features)
        
        # –ú–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–µ—Ç–∫–∏
        label_counts = segment['exercise_type'].value_counts()
        if not label_counts.empty:
            labels.append(label_counts.index[0])
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if idx % 10 == 0:
            progress = (idx + 1) / total_segments
            progress_bar.progress(min(progress, 1.0))
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {idx + 1} / {total_segments}")
    
    progress_bar.empty()
    status_text.empty()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    feature_df = pd.DataFrame(segments)
    feature_df['exercise_type'] = labels
    
    return feature_df
# ==================== –§–£–ù–ö–¶–ò–ò –û–ë–£–ß–ï–ù–ò–Ø ====================

def train_model(model_type, X_train, X_test, y_train, y_test):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
    
    # –ö–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏ –¥–ª—è XGBoost (—Ç—Ä–µ–±—É–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç–∫–∏)
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)
    
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),
        'SVM': SVC(kernel='rbf', probability=True, random_state=42),
        'XGBoost': XGBClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1, eval_metric='mlogloss'),
        'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),
        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, n_jobs=-1)
    }
    
    model = models[model_type]
    
    # –û–±—É—á–µ–Ω–∏–µ (XGBoost —Ç—Ä–µ–±—É–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç–∫–∏)
    if model_type == 'XGBoost':
        model.fit(X_train, y_train_encoded)
    else:
        model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–¥–µ–∫–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è XGBoost)
    if model_type == 'XGBoost':
        y_pred_encoded = model.predict(X_test)
        y_pred = label_encoder.inverse_transform(y_pred_encoded)
        y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
    else:
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏)
    if model_type == 'XGBoost':
        cv_scores = cross_val_score(model, X_train, y_train_encoded, cv=5, n_jobs=-1)
    else:
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1)
    
    metrics = {
        'model': model,
        'label_encoder': label_encoder if model_type == 'XGBoost' else None,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'confusion_matrix': confusion_matrix(y_test, y_pred),
        'classification_report': classification_report(y_test, y_pred, output_dict=True, zero_division=0)
    }
    
    return metrics


def plot_confusion_matrix(cm, classes):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"""
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)
    ax.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', fontsize=16, fontweight='bold')
    ax.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏', fontsize=12)
    ax.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    return fig


def plot_feature_importance(model, feature_names, top_n=20):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    if hasattr(model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False).head(top_n)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.barplot(data=importance_df, y='feature', x='importance', palette='viridis', ax=ax)
        ax.set_title(f'–¢–æ–ø-{top_n} –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16, fontweight='bold')
        ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å', fontsize=12)
        ax.set_ylabel('–ü—Ä–∏–∑–Ω–∞–∫', fontsize=12)
        plt.tight_layout()
        return fig
    return None


def plot_class_accuracy(y_test, y_pred, classes):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º"""
    class_accuracy = []
    for class_name in classes:
        class_mask = y_test == class_name
        if np.sum(class_mask) > 0:
            acc = np.mean(y_pred[class_mask] == class_name)
            class_accuracy.append(acc)
        else:
            class_accuracy.append(0)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars = ax.bar(classes, class_accuracy, color='skyblue', edgecolor='navy')
    ax.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π', fontsize=16, fontweight='bold')
    ax.set_xlabel('–ö–ª–∞—Å—Å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è', fontsize=12)
    ax.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    ax.set_ylim([0, 1.1])
    plt.xticks(rotation=45, ha='right')
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, acc in zip(bars, class_accuracy):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{acc:.2f}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    return fig


def create_models_comparison_table(all_models):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    comparison_data = []
    
    for model_name, metrics in all_models.items():
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—Å—Ä–µ–¥–Ω—é—é –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ –≤—Å–µ–º –ø—Ä–∏–º–µ—Ä–∞–º)
        if metrics['y_pred_proba'] is not None:
            avg_confidence = np.mean(np.max(metrics['y_pred_proba'], axis=1))
        else:
            avg_confidence = None
        
        comparison_data.append({
            '–ú–æ–¥–µ–ª—å': model_name,
            '–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)': f"{metrics['accuracy']:.4f}",
            '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence)': f"{avg_confidence:.4f}" if avg_confidence else "N/A",
            '–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç. (Precision)': f"{metrics['precision']:.4f}",
            '–ü–æ–ª–Ω–æ—Ç–∞ (Recall)': f"{metrics['recall']:.4f}",
            'F1-–º–µ—Ä–∞': f"{metrics['f1_score']:.4f}",
            'CV —Å—Ä–µ–¥–Ω–µ–µ': f"{metrics['cv_mean']:.4f}",
            'CV –æ—Ç–∫–ª.': f"{metrics['cv_std']:.4f}"
        })
    
    df = pd.DataFrame(comparison_data)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¢–æ—á–Ω–æ—Å—Ç–∏
    df = df.sort_values('–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)', ascending=False).reset_index(drop=True)
    
    return df


def plot_models_comparison(all_models):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    model_names = list(all_models.keys())
    accuracies = [all_models[name]['accuracy'] for name in model_names]
    f1_scores = [all_models[name]['f1_score'] for name in model_names]
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ accuracy
    sorted_indices = np.argsort(accuracies)[::-1]
    model_names = [model_names[i] for i in sorted_indices]
    accuracies = [accuracies[i] for i in sorted_indices]
    f1_scores = [f1_scores[i] for i in sorted_indices]
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    x = np.arange(len(model_names))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy', color='steelblue', alpha=0.8)
    bars2 = ax.bar(x + width/2, f1_scores, width, label='F1-Score', color='coral', alpha=0.8)
    
    ax.set_xlabel('–ú–æ–¥–µ–ª–∏', fontsize=12, fontweight='bold')
    ax.set_ylabel('–ú–µ—Ç—Ä–∏–∫–∞', fontsize=12, fontweight='bold')
    ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º', fontsize=16, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(model_names, rotation=45, ha='right')
    ax.legend()
    ax.set_ylim([0, 1.1])
    ax.grid(axis='y', alpha=0.3)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    return fig


# ==================== –ò–ù–¢–ï–†–§–ï–ô–° ====================

# –°–µ–∫—Ü–∏—è 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
st.header("üìÅ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

data_source = st.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:",
    [
        "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤",
        "üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª",
        "üß™ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ",
    ],
    horizontal=False,
    index=0
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = None

if data_source == "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP –∞—Ä—Ö–∏–≤":
    uploaded_zip = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤ —Å TXT —Ñ–∞–π–ª–∞–º–∏", type=['zip'])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è
    sample_rate = st.slider(
        "–ü—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)",
        min_value=1, max_value=10, value=2,
        help="1 = –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, 2 = –∫–∞–∂–¥–∞—è –≤—Ç–æ—Ä–∞—è –∑–∞–ø–∏—Å—å, 10 = –∫–∞–∂–¥–∞—è –¥–µ—Å—è—Ç–∞—è"
    )
    
    if uploaded_zip is not None:
        if st.button("üîì –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å", type="primary"):
            data = load_from_zip(uploaded_zip, sample_rate)
            if data is not None:
                st.session_state['raw_data'] = data

elif data_source == "üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª":
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º", type=['csv'])
    if uploaded_file is not None:
        try:
            data = pd.read_csv(uploaded_file)
            st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
            st.session_state['raw_data'] = data
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")

elif data_source == "üß™ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ":
    if st.button("üé≤ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ", type="primary"):
        data = load_demo_data()
        st.session_state['raw_data'] = data

# –í–°–ï–ì–î–ê –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session_state
if 'raw_data' in st.session_state:
    data = st.session_state['raw_data']

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
if data is not None:
    st.subheader("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", f"{len(data):,}")
    col2.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", len(data.columns) - 1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –º–µ—Ç–∫–∞–º–∏
    label_col = None
    for col in ['Workout', 'Exercise', 'exercise_type', 'label', 'class']:
        if col in data.columns:
            label_col = col
            break
    
    if label_col:
        col3.metric("–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–π", data[label_col].nunique())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—É–±—ä–µ–∫—Ç–∞—Ö
    subject_col = None
    for col in ['Subject', 'User', 'subject', 'user']:
        if col in data.columns:
            subject_col = col
            break
    
    if subject_col:
        col4.metric("–°—É–±—ä–µ–∫—Ç–æ–≤", data[subject_col].nunique())
    
    with st.expander("üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
        st.dataframe(data.head(100), use_container_width=True)
    
    if label_col:
        with st.expander("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π"):
            workout_counts = data[label_col].value_counts()
            fig, ax = plt.subplots(figsize=(12, 6))
            workout_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='navy')
            ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ', fontsize=14, fontweight='bold')
            ax.set_xlabel('–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ')
            ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    st.markdown("---")
    
    # –°–µ–∫—Ü–∏—è 2: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    st.header("üîÑ 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    col1, col2 = st.columns(2)
    with col1:
        window_size = st.slider("–†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π)", 20, 100, 50, 5)
    with col2:
        overlap = st.slider("–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –æ–∫–æ–Ω", 0.0, 0.9, 0.5, 0.1)
    
    if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
        with st.spinner("‚è≥ –ò–¥—ë—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            processed_data = preprocess_data(data, window_size, overlap)
            st.session_state['processed_data'] = processed_data
            st.success(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(processed_data)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤.")
    
    # –°–µ–∫—Ü–∏—è 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    if 'processed_data' in st.session_state:
        st.markdown("---")
        st.header("ü§ñ 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
        
        processed_data = st.session_state['processed_data']
        
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –æ–±—É—á–µ–Ω–∏—è
        training_mode = st.radio(
            "–†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è:",
            ["üéØ –û–¥–Ω–∞ –º–æ–¥–µ–ª—å", "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"],
            horizontal=True
        )
        
        test_size = st.slider("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏", 0.1, 0.4, 0.2, 0.05)
        
        if training_mode == "üéØ –û–¥–Ω–∞ –º–æ–¥–µ–ª—å":
            # –†–µ–∂–∏–º –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
            model_type = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
                ['Random Forest', 'Logistic Regression', 'SVM', 'XGBoost', 'Decision Tree', 'K-Nearest Neighbors']
            )
            
            if st.button("üéØ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                with st.spinner(f"‚è≥ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_type}..."):
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    X = processed_data.drop(columns=['exercise_type'])
                    y = processed_data['exercise_type']
                    
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y, test_size=test_size, random_state=42, stratify=y
                    )
                    
                    # –û–±—É—á–µ–Ω–∏–µ
                    metrics = train_model(model_type, X_train, X_test, y_train, y_test)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
                    st.session_state['metrics'] = metrics
                    st.session_state['X_test'] = X_test
                    st.session_state['y_test'] = y_test
                    st.session_state['scaler'] = scaler
                    st.session_state['feature_names'] = X.columns.tolist()
                    st.session_state['model_type'] = model_type
                    st.session_state['all_models'] = {model_type: metrics}
                    
                    st.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_type} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
        
        else:
            # –†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            st.info("üí° –ë—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            
            model_types = ['Random Forest', 'Logistic Regression', 'SVM', 'XGBoost', 
                          'Decision Tree', 'K-Nearest Neighbors']
            
            if st.button("üöÄ –û–±—É—á–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏", type="primary"):
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–∏–Ω —Ä–∞–∑
                X = processed_data.drop(columns=['exercise_type'])
                y = processed_data['exercise_type']
                
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=test_size, random_state=42, stratify=y
                )
                
                # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
                all_models = {}
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for idx, model_type in enumerate(model_types):
                    status_text.text(f"‚è≥ –û–±—É—á–µ–Ω–∏–µ {model_type}... ({idx+1}/{len(model_types)})")
                    
                    try:
                        metrics = train_model(model_type, X_train, X_test, y_train, y_test)
                        all_models[model_type] = metrics
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {model_type}: {str(e)}")
                    
                    progress_bar.progress((idx + 1) / len(model_types))
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.session_state['all_models'] = all_models
                st.session_state['X_test'] = X_test
                st.session_state['y_test'] = y_test
                st.session_state['scaler'] = scaler
                st.session_state['feature_names'] = X.columns.tolist()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é
                best_model_name = max(all_models.keys(), key=lambda k: all_models[k]['accuracy'])
                st.session_state['metrics'] = all_models[best_model_name]
                st.session_state['model_type'] = best_model_name
                
                status_text.empty()
                progress_bar.empty()
                st.success(f"‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã! –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
        
        # –°–µ–∫—Ü–∏—è 3.5: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ)
        if 'all_models' in st.session_state and len(st.session_state['all_models']) > 1:
            st.markdown("---")
            st.header("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
            
            all_models = st.session_state['all_models']
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            st.subheader("üìã –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
            comparison_df = create_models_comparison_table(all_models)
            
            # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –ª—É—á—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            styled_df = comparison_df.style.highlight_max(
                subset=['–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)', '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence)', '–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç. (Precision)', 
                        '–ü–æ–ª–Ω–æ—Ç–∞ (Recall)', 'F1-–º–µ—Ä–∞', 'CV —Å—Ä–µ–¥–Ω–µ–µ'],
                color='lightgreen'
            ).highlight_min(
                subset=['CV –æ—Ç–∫–ª.'],
                color='lightgreen'
            )
            
            st.dataframe(styled_df, use_container_width=True, height=300)
            
            # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            st.subheader("üìà –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ")
            fig_comparison = plot_models_comparison(all_models)
            st.pyplot(fig_comparison)
            plt.close()
            
            # –í—ã–≤–æ–¥ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model = max(all_models.keys(), key=lambda k: all_models[k]['accuracy'])
            st.success(f"üèÜ **–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:** {best_model} (Accuracy: {all_models[best_model]['accuracy']:.4f})")
            
            # üìù –¢–µ–∫—Å—Ç–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —à–∞–±–ª–æ–Ω—É
            st.markdown("---")
            st.subheader("üìù –í—ã–≤–æ–¥—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            test_size = st.session_state.get('test_size_used', 0.2)
            best_accuracy = all_models[best_model]['accuracy']
            best_precision = all_models[best_model]['precision']
            best_recall = all_models[best_model]['recall']
            best_f1 = all_models[best_model]['f1_score']
            
            # –ù–∞—Ö–æ–¥–∏–º –º–æ–¥–µ–ª—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (—Å—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º CV Mean –∫–∞–∫ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            best_confidence_model = max(all_models.keys(), key=lambda k: all_models[k]['cv_mean'])
            best_confidence = all_models[best_confidence_model]['cv_mean']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
            conclusion_text = f"""
–ü—Ä–∏ –∑–∞–¥–∞–Ω–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ **{test_size:.1%}** ({int(test_size*100)}% –æ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö) –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ 
{len(all_models)} –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π.

**–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è** –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–∞ –º–æ–¥–µ–ª—å **{best_model}** —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏:
- **–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)**: {best_accuracy:.4f} ({best_accuracy*100:.2f}%) ‚Äî –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤
- **–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö (Precision)**: {best_precision:.4f} ({best_precision*100:.2f}%) ‚Äî –¥–æ–ª—è –∏—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö
- **–ü–æ–ª–Ω–æ—Ç–∞ (Recall)**: {best_recall:.4f} ({best_recall*100:.2f}%) ‚Äî –¥–æ–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—Ç –≤—Å–µ—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –≤ –≤—ã–±–æ—Ä–∫–µ
- **F1-–º–µ—Ä–∞ (F1-Score)**: {best_f1:.4f} ({best_f1*100:.2f}%) ‚Äî –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É Precision –∏ Recall

**–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å** (—Å—Ä–µ–¥–Ω—é—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏) –ø–æ–∫–∞–∑–∞–ª–∞ –º–æ–¥–µ–ª—å **{best_confidence_model}** 
—Å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º **{best_confidence:.4f}** ({best_confidence*100:.2f}%), —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞—Ö –¥–∞–Ω–Ω—ã—Ö.

**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence)** ‚Äî —ç—Ç–æ —Å—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª—å –æ—Ç–Ω–æ—Å–∏—Ç –æ–±—ä–µ–∫—Ç—ã –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º (–æ—Ç 0 –¥–æ 1 –∏–ª–∏ 0-100%). 
–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>70%) —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ç–æ, —á—Ç–æ –º–æ–¥–µ–ª—å —á—ë—Ç–∫–æ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.

**–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)** ‚Äî —ç—Ç–æ –æ–±—â–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π 
–Ω–∞ –≤—Å–µ–π —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∫ –∏—Ö –æ–±—â–µ–º—É —á–∏—Å–ª—É.

**–ó–∞–∫–ª—é—á–µ–Ω–∏–µ:** {'–ú–æ–¥–µ–ª—å ' + best_model + ' —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π.' if best_model == best_confidence_model else f'–ú–æ–¥–µ–ª–∏ {best_model} (–ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏) –∏ {best_confidence_model} (–ø–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏) –ø–æ–∫–∞–∑–∞–ª–∏ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.'}
            """
            
            st.info(conclusion_text)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π –º–µ—Ç—Ä–∏–∫
            with st.expander("üìñ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –º–µ—Ç—Ä–∏–∫"):
                st.markdown("""
                **–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)** ‚Äî –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: `(–ò–ü + –ò–û) / –í—Å–µ–≥–æ`
                - –§–æ—Ä–º—É–ª–∞: `(TP + TN) / (TP + TN + FP + FN)`
                - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                
                **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence)** ‚Äî —Å—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                - –í—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ —Å—Ä–µ–¥–Ω–µ–µ –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ –≤—Å–µ–º –ø—Ä–∏–º–µ—Ä–∞–º
                - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö
                - –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>0.7) ‚Äî –º–æ–¥–µ–ª—å —á—ë—Ç–∫–æ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –∫–ª–∞—Å—Å—ã
                
                **–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö (Precision)** ‚Äî –¥–æ–ª—è –∏—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: `–ò–ü / (–ò–ü + –õ–ü)`
                - –§–æ—Ä–º—É–ª–∞: `TP / (TP + FP)`
                - –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å: "–ò–∑ —Ç–æ–≥–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞–∑–≤–∞–ª–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º, —Å–∫–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ?"
                
                **–ü–æ–ª–Ω–æ—Ç–∞ (Recall)** ‚Äî –¥–æ–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: `–ò–ü / (–ò–ü + –õ–û)`
                - –§–æ—Ä–º—É–ª–∞: `TP / (TP + FN)`
                - –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å: "–ò–∑ –≤—Å–µ—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, —Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –Ω–∞—à–ª–∞?"
                
                **F1-–º–µ—Ä–∞ (F1-Score)** ‚Äî –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ Precision –∏ Recall
                - –§–æ—Ä–º—É–ª–∞: `2 * (Precision * Recall) / (Precision + Recall)`
                - –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –ø–æ–ª–Ω–æ—Ç–æ–π
                
                **CV —Å—Ä–µ–¥–Ω–µ–µ (CV Mean)** ‚Äî —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
                - –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ K —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞—Ö –¥–∞–Ω–Ω—ã—Ö
                - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                
                **CV –æ—Ç–∫–ª. (CV Std)** ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
                - –†–∞–∑–±—Ä–æ—Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞–º–∏
                - –ß–µ–º –º–µ–Ω—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –º–æ–¥–µ–ª—å
                
                ---
                **–û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è:**
                - **–ò–ü (TP)** ‚Äî –ò—Å—Ç–∏–Ω–Ω–æ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ (True Positive) ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                - **–ò–û (TN)** ‚Äî –ò—Å—Ç–∏–Ω–Ω–æ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ (True Negative) ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
                - **–õ–ü (FP)** ‚Äî –õ–æ–∂–Ω–æ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ (False Positive) ‚Äî –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                - **–õ–û (FN)** ‚Äî –õ–æ–∂–Ω–æ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ (False Negative) ‚Äî –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
                """)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º test_size –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤—ã–≤–æ–¥–∞—Ö
            if 'X_test' in st.session_state and 'processed_data' in st.session_state:
                total_samples = len(st.session_state['processed_data'])
                test_samples = len(st.session_state['X_test'])
                actual_test_size = test_samples / total_samples if total_samples > 0 else test_size
                st.session_state['test_size_used'] = actual_test_size
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            st.markdown("---")
            st.subheader("üîç –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–æ–¥–µ–ª—è–º")
            st.info("üëá –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            
            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            selected_model_name = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
                list(all_models.keys()),
                index=list(all_models.keys()).index(best_model)
            )
            
            if selected_model_name:
                selected_metrics = all_models[selected_model_name]
                
                st.markdown(f"### üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: **{selected_model_name}**")
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("Accuracy", f"{selected_metrics['accuracy']:.4f}")
                col2.metric("Precision", f"{selected_metrics['precision']:.4f}")
                col3.metric("Recall", f"{selected_metrics['recall']:.4f}")
                col4.metric("F1-Score", f"{selected_metrics['f1_score']:.4f}")
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ç–∞–±–∞—Ö
                tab1, tab2, tab3, tab4 = st.tabs([
                    "üìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", 
                    "üéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", 
                    "üìà –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º", 
                    "üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç"
                ])
                
                classes = np.unique(st.session_state['y_test'])
                
                with tab1:
                    st.markdown(f"**–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è {selected_model_name}**")
                    fig_cm = plot_confusion_matrix(selected_metrics['confusion_matrix'], classes)
                    st.pyplot(fig_cm)
                    plt.close()
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    with st.expander("‚ÑπÔ∏è –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"):
                        st.markdown("""
                        - **–î–∏–∞–≥–æ–Ω–∞–ª—å** ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        - **–í–Ω–µ –¥–∏–∞–≥–æ–Ω–∞–ª–∏** ‚Äî –æ—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                        - –ß–µ–º —Ç–µ–º–Ω–µ–µ —Ü–≤–µ—Ç –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏, —Ç–µ–º –ª—É—á—à–µ
                        """)
                
                with tab2:
                    st.markdown(f"**–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {selected_model_name}**")
                    fig_fi = plot_feature_importance(selected_metrics['model'], st.session_state['feature_names'])
                    if fig_fi:
                        st.pyplot(fig_fi)
                        plt.close()
                    else:
                        st.info(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {selected_model_name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                
                with tab3:
                    st.markdown(f"**–¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è–º –¥–ª—è {selected_model_name}**")
                    fig_ca = plot_class_accuracy(
                        st.session_state['y_test'], 
                        selected_metrics['y_pred'], 
                        classes
                    )
                    st.pyplot(fig_ca)
                    plt.close()
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    with st.expander("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º"):
                        class_stats = []
                        for class_name in classes:
                            mask = st.session_state['y_test'] == class_name
                            total = np.sum(mask)
                            correct = np.sum(selected_metrics['y_pred'][mask] == class_name)
                            accuracy = correct / total if total > 0 else 0
                            
                            class_stats.append({
                                '–ö–ª–∞—Å—Å': class_name,
                                '–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤': total,
                                '–ü—Ä–∞–≤–∏–ª—å–Ω–æ': correct,
                                '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ': total - correct,
                                '–¢–æ—á–Ω–æ—Å—Ç—å': f"{accuracy:.2%}"
                            })
                        
                        stats_df = pd.DataFrame(class_stats)
                        st.dataframe(stats_df, use_container_width=True)
                
                with tab4:
                    st.markdown(f"**–ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è {selected_model_name}**")
                    report_df = pd.DataFrame(selected_metrics['classification_report']).transpose()
                    st.dataframe(report_df, use_container_width=True)
                    
                    # –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                    st.markdown("**üìä –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫:**")
                    col1, col2, col3 = st.columns(3)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º weighted avg –∏–∑ –æ—Ç—á—ë—Ç–∞
                    if 'weighted avg' in selected_metrics['classification_report']:
                        weighted_avg = selected_metrics['classification_report']['weighted avg']
                        col1.metric("Weighted Precision", f"{weighted_avg['precision']:.4f}")
                        col2.metric("Weighted Recall", f"{weighted_avg['recall']:.4f}")
                        col3.metric("Weighted F1-Score", f"{weighted_avg['f1-score']:.4f}")


        
        # –°–µ–∫—Ü–∏—è 4: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if 'metrics' in st.session_state:
            st.markdown("---")
            st.header("üìä 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
            
            metrics = st.session_state['metrics']
            model_type = st.session_state['model_type']
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            st.subheader(f"üìà –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏: {model_type}")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Accuracy", f"{metrics['accuracy']:.4f}")
            col2.metric("Precision", f"{metrics['precision']:.4f}")
            col3.metric("Recall", f"{metrics['recall']:.4f}")
            col4.metric("F1-Score", f"{metrics['f1_score']:.4f}")
            
            col1, col2 = st.columns(2)
            col1.metric("CV Mean", f"{metrics['cv_mean']:.4f}")
            col2.metric("CV Std", f"{metrics['cv_std']:.4f}")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            
            tab1, tab2, tab3, tab4 = st.tabs(["–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", "–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", "–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º", "–û—Ç—á—ë—Ç"])
            
            with tab1:
                classes = np.unique(st.session_state['y_test'])
                fig_cm = plot_confusion_matrix(metrics['confusion_matrix'], classes)
                st.pyplot(fig_cm)
                plt.close()
            
            with tab2:
                fig_fi = plot_feature_importance(metrics['model'], st.session_state['feature_names'])
                if fig_fi:
                    st.pyplot(fig_fi)
                    plt.close()
                else:
                    st.info("–î–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            with tab3:
                fig_ca = plot_class_accuracy(st.session_state['y_test'], metrics['y_pred'], classes)
                st.pyplot(fig_ca)
                plt.close()
            
            with tab4:
                st.text("–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
                report_df = pd.DataFrame(metrics['classification_report']).transpose()
                st.dataframe(report_df, use_container_width=True)
            
            # –°–µ–∫—Ü–∏—è 5: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            st.markdown("---")
            st.header("üîÆ 5. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
            st.info("üí° –í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞—Ç—á–∏–∫–æ–≤ –≤—Ä—É—á–Ω—É—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–∏–ø–∞ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è")
            
            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–µ—Å–ª–∏ –æ–±—É—á–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
            if 'all_models' in st.session_state and len(st.session_state['all_models']) > 1:
                prediction_model_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:",
                    list(st.session_state['all_models'].keys()),
                    key='prediction_model_select'
                )
                prediction_model = st.session_state['all_models'][prediction_model_name]['model']
                st.caption(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: **{prediction_model_name}**")
            else:
                prediction_model = metrics['model']
                prediction_model_name = st.session_state.get('model_type', '–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å')
            
            with st.form("prediction_form"):
                st.markdown("### üìù –í–≤–æ–¥ –∑–Ω–∞—á–µ–Ω–∏–π –¥–∞—Ç—á–∏–∫–æ–≤")
                st.caption("–ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–æ–∫–æ—è")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**–ê–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä (–º/—Å¬≤)**")
                    a_x = st.number_input("A_x", value=0.0, format="%.3f", help="–£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ –æ—Å–∏ X")
                    a_y = st.number_input("A_y", value=-9.8, format="%.3f", help="–£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ –æ—Å–∏ Y (–≥—Ä–∞–≤–∏—Ç–∞—Ü–∏—è)")
                    a_z = st.number_input("A_z", value=0.0, format="%.3f", help="–£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ –æ—Å–∏ Z")
                
                with col2:
                    st.markdown("**–ì–∏—Ä–æ—Å–∫–æ–ø (—Ä–∞–¥/—Å)**")
                    g_x = st.number_input("G_x", value=0.0, format="%.3f", help="–£–≥–ª–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ –æ—Å–∏ X")
                    g_y = st.number_input("G_y", value=0.0, format="%.3f", help="–£–≥–ª–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ –æ—Å–∏ Y")
                    g_z = st.number_input("G_z", value=0.0, format="%.3f", help="–£–≥–ª–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ –æ—Å–∏ Z")
                
                with col3:
                    st.markdown("**–ú–∞–≥–Ω–∏—Ç–æ–º–µ—Ç—Ä (–µ–¥–∏–Ω–∏—Ü—ã)**")
                    m_x = st.number_input("M_x", value=0.6, format="%.3f", help="–ú–∞–≥–Ω–∏—Ç–Ω–æ–µ –ø–æ–ª–µ –ø–æ –æ—Å–∏ X")
                    m_y = st.number_input("M_y", value=0.45, format="%.3f", help="–ú–∞–≥–Ω–∏—Ç–Ω–æ–µ –ø–æ–ª–µ –ø–æ –æ—Å–∏ Y")
                    m_z = st.number_input("M_z", value=-0.08, format="%.3f", help="–ú–∞–≥–Ω–∏—Ç–Ω–æ–µ –ø–æ–ª–µ –ø–æ –æ—Å–∏ Z")
                
                # –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π
                with st.expander("üìã –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π"):
                    st.markdown("""
                    **–ü—Ä–∏–º–µ—Ä 1: –ü—Ä–∏—Å–µ–¥–∞–Ω–∏–µ**
                    - A_x: 0.5, A_y: -8.0, A_z: 2.0
                    - G_x: 0.1, G_y: 0.2, G_z: -0.1
                    - M_x: 0.58, M_y: 0.43, M_z: -0.09
                    
                    **–ü—Ä–∏–º–µ—Ä 2: –ü—Ä—ã–∂–æ–∫**
                    - A_x: 1.5, A_y: -5.0, A_z: 3.5
                    - G_x: 0.8, G_y: 1.2, G_z: 0.5
                    - M_x: 0.62, M_y: 0.47, M_z: -0.07
                    
                    **–ü—Ä–∏–º–µ—Ä 3: –ú–∞—Ö–∏ —Ä—É–∫–∞–º–∏**
                    - A_x: 2.0, A_y: -9.0, A_z: 1.0
                    - G_x: 1.5, G_y: 0.3, G_z: 0.8
                    - M_x: 0.55, M_y: 0.40, M_z: -0.10
                    """)
                
                submit = st.form_submit_button("üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ", type="primary", use_container_width=True)
                
                if submit:
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    st.markdown("---")
                    st.markdown("### üìä –í–≤–µ–¥—ë–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞—Ç—á–∏–∫–æ–≤")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–ê–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä X", f"{a_x:.3f} –º/—Å¬≤")
                        st.metric("–ê–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä Y", f"{a_y:.3f} –º/—Å¬≤")
                        st.metric("–ê–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä Z", f"{a_z:.3f} –º/—Å¬≤")
                    with col2:
                        st.metric("–ì–∏—Ä–æ—Å–∫–æ–ø X", f"{g_x:.3f} —Ä–∞–¥/—Å")
                        st.metric("–ì–∏—Ä–æ—Å–∫–æ–ø Y", f"{g_y:.3f} —Ä–∞–¥/—Å")
                        st.metric("–ì–∏—Ä–æ—Å–∫–æ–ø Z", f"{g_z:.3f} —Ä–∞–¥/—Å")
                    with col3:
                        st.metric("–ú–∞–≥–Ω–∏—Ç–æ–º–µ—Ç—Ä X", f"{m_x:.3f}")
                        st.metric("–ú–∞–≥–Ω–∏—Ç–æ–º–µ—Ç—Ä Y", f"{m_y:.3f}")
                        st.metric("–ú–∞–≥–Ω–∏—Ç–æ–º–µ—Ç—Ä Z", f"{m_z:.3f}")
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    accel_magnitude = np.sqrt(a_x**2 + a_y**2 + a_z**2)
                    gyro_magnitude = np.sqrt(g_x**2 + g_y**2 + g_z**2)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ–∫–Ω–∞)
                    window_data = pd.DataFrame([{
                        'accel_x': a_x, 'accel_y': a_y, 'accel_z': a_z,
                        'gyro_x': g_x, 'gyro_y': g_y, 'gyro_z': g_z,
                        'accel_magnitude': accel_magnitude,
                        'gyro_magnitude': gyro_magnitude
                    }] * 50)  # –ü–æ–≤—Ç–æ—Ä—è–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–Ω–∞
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z',
                                   'accel_magnitude', 'gyro_magnitude']
                    features = extract_window_features(window_data, sensor_cols)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º —Å—Ç–æ–ª–±—Ü–æ–≤
                    feature_df = pd.DataFrame([features])
                    feature_df = feature_df[st.session_state['feature_names']]
                    
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                    X_pred = st.session_state['scaler'].transform(feature_df)
                    
                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (—Å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è XGBoost)
                    if 'all_models' in st.session_state and prediction_model_name in st.session_state['all_models']:
                        model_metrics = st.session_state['all_models'][prediction_model_name]
                        label_encoder = model_metrics.get('label_encoder', None)
                        
                        if label_encoder is not None:  # XGBoost
                            pred_encoded = prediction_model.predict(X_pred)[0]
                            prediction = label_encoder.inverse_transform([pred_encoded])[0]
                        else:
                            prediction = prediction_model.predict(X_pred)[0]
                    else:
                        prediction = prediction_model.predict(X_pred)[0]
                    
                    st.markdown("---")
                    st.markdown("### üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
                    
                    if hasattr(prediction_model, 'predict_proba'):
                        proba = prediction_model.predict_proba(X_pred)[0]
                        confidence = np.max(proba)
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ (—Å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è XGBoost)
                        if 'all_models' in st.session_state and prediction_model_name in st.session_state['all_models']:
                            model_metrics = st.session_state['all_models'][prediction_model_name]
                            label_encoder = model_metrics.get('label_encoder', None)
                            
                            if label_encoder is not None:  # XGBoost
                                class_names = label_encoder.classes_
                            else:
                                class_names = prediction_model.classes_
                        else:
                            class_names = prediction_model.classes_
                        
                        # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        col1, col2 = st.columns([2, 1])
                        with col1:
                            st.success(f"# üèãÔ∏è {prediction}")
                            st.caption(f"–ú–æ–¥–µ–ª—å: {prediction_model_name}")
                            
                            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ all_models
                            if 'all_models' in st.session_state and prediction_model_name in st.session_state['all_models']:
                                model_accuracy = st.session_state['all_models'][prediction_model_name]['accuracy']
                                st.caption(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (Accuracy): {model_accuracy:.1%} ‚Äî –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
                        
                        with col2:
                            st.metric(
                                "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence)", 
                                f"{confidence:.1%}", 
                                delta=f"{(confidence - 1/len(proba)):.1%}",
                                delta_color="off",
                                help="–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ (–æ—Ç 0% –¥–æ 100%)"
                            )
                            st.caption("üí° –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º—É —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—é")
                        
                        # –¢–∞–±–ª–∏—Ü–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        st.markdown("#### üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º:")
                        proba_df = pd.DataFrame({
                            '–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ': prediction_model.classes_,
                            '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': proba,
                            '–ü—Ä–æ—Ü–µ–Ω—Ç': [f"{p:.2%}" for p in proba]
                        }).sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False).reset_index(drop=True)
                        
                        # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                        def highlight_max(s):
                            is_max = s == s.max()
                            return ['background-color: lightgreen' if v else '' for v in is_max]
                        
                        styled_proba = proba_df.style.apply(highlight_max, subset=['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'])
                        st.dataframe(styled_proba, use_container_width=True, height=350)
                        
                        # –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        st.markdown("#### üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:")
                        fig, ax = plt.subplots(figsize=(10, 6))
                        
                        colors = ['lightcoral' if i != 0 else 'steelblue' 
                                 for i in range(len(proba_df))]
                        
                        bars = ax.barh(proba_df['–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ'], proba_df['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'], 
                                      color=colors, edgecolor='navy', linewidth=1.5)
                        ax.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', fontsize=12, fontweight='bold')
                        ax.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ({prediction_model_name})', 
                                   fontsize=14, fontweight='bold')
                        ax.set_xlim([0, 1])
                        ax.grid(axis='x', alpha=0.3)
                        
                        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
                        for i, (bar, prob) in enumerate(zip(bars, proba_df['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'])):
                            ax.text(prob + 0.02, bar.get_y() + bar.get_height()/2,
                                   f'{prob:.1%}', va='center', fontsize=10, fontweight='bold')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close()
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                        with st.expander("‚ÑπÔ∏è –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"):
                            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                            model_accuracy = "N/A"
                            if 'all_models' in st.session_state and prediction_model_name in st.session_state['all_models']:
                                model_accuracy = f"{st.session_state['all_models'][prediction_model_name]['accuracy']:.1%}"
                            
                            st.markdown(f"""
                            **–ö–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
                            
                            **üìä –î–≤–∞ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏—è:**
                            
                            1. **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (Confidence):** `{confidence:.1%}`
                               - –≠—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∏–º–µ–Ω–Ω–æ –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º—É –∫–ª–∞—Å—Å—É
                               - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ **—ç—Ç–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏**
                               - –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
                               - **–î–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞** (—Ç–µ–∫—É—â–µ–≥–æ –≤–≤–æ–¥–∞)
                            
                            2. **–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (Accuracy):** `{model_accuracy}`
                               - –≠—Ç–æ –æ–±—â–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ–π —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
                               - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ª—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
                               - –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫: (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è) / (–≤—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤)
                               - **–î–ª—è –≤—Å–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö**
                            
                            **–†–∞–∑–Ω–∏—Ü–∞:** –¢–æ—á–Ω–æ—Å—Ç—å ‚Äî —ç—Ç–æ –æ–±—â–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏, –∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚Äî —ç—Ç–æ –µ—ë —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Å–ª—É—á–∞–µ.
                            
                            ---
                            
                            **–¢–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:**
                            - **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ:** `{prediction}` ‚Äî –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
                            - **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** `{confidence:.1%}` ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞
                            - **–ü–æ—Ä–æ–≥ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏:** –û–±—ã—á–Ω–æ >70% —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∞–¥—ë–∂–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
                            
                            **–°—Ç–∞—Ç—É—Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** {'‚úÖ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>70%) ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–¥—ë–∂–Ω–æ' if confidence > 0.7 
                                               else '‚ö†Ô∏è –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (50-70%) ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –≤–µ—Ä–Ω–æ' if confidence > 0.5 
                                               else '‚ùå –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<50%) ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ'}
                            
                            **–ß—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:**
                            {'–ú–æ–¥–µ–ª—å —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ. –ú–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É.' if confidence > 0.7
                             else '–ú–æ–¥–µ–ª—å —Å–æ–º–Ω–µ–≤–∞–µ—Ç—Å—è –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–ª–∞—Å—Å–∞–º–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä—É–≥–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏.' if confidence > 0.5
                             else '–ú–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ. –í–æ–∑–º–æ–∂–Ω–æ, –¥–∞–Ω–Ω—ã–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ —Ä–∞–º–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏.'}
                            """)
                        
                        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                        if 'all_models' in st.session_state and len(st.session_state['all_models']) > 1:
                            with st.expander("üîÑ –°—Ä–∞–≤–Ω–∏—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏"):
                                st.markdown("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**")
                                st.caption("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é—Ç –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø—Ä–∏–º–µ—Ä")
                                
                                comparison_results = []
                                for model_name, model_metrics in st.session_state['all_models'].items():
                                    model_obj = model_metrics['model']
                                    label_encoder_m = model_metrics.get('label_encoder', None)
                                    
                                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è XGBoost
                                    if label_encoder_m is not None:
                                        pred_encoded = model_obj.predict(X_pred)[0]
                                        pred = label_encoder_m.inverse_transform([pred_encoded])[0]
                                    else:
                                        pred = model_obj.predict(X_pred)[0]
                                    
                                    # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                                    if hasattr(model_obj, 'predict_proba'):
                                        prob = model_obj.predict_proba(X_pred)[0]
                                        conf = np.max(prob)
                                    else:
                                        conf = None
                                    
                                    # –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                                    accuracy = model_metrics['accuracy']
                                    
                                    comparison_results.append({
                                        '–ú–æ–¥–µ–ª—å': model_name,
                                        '–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏': f"{accuracy:.2%}",
                                        '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ': pred,
                                        '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{conf:.2%}" if conf else "N/A",
                                        '–°–æ–≤–ø–∞–¥–∞–µ—Ç': '‚úÖ' if pred == prediction else '‚ùå'
                                    })
                                
                                comp_df = pd.DataFrame(comparison_results)
                                
                                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
                                comp_df['_accuracy_sort'] = comp_df['–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏'].str.rstrip('%').astype(float)
                                comp_df = comp_df.sort_values('_accuracy_sort', ascending=False).drop('_accuracy_sort', axis=1)
                                
                                st.dataframe(comp_df, use_container_width=True)
                                
                                # –ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã
                                matching_models = sum(1 for r in comparison_results if r['–°–æ–≤–ø–∞–¥–∞–µ—Ç'] == '‚úÖ')
                                total_models = len(comparison_results)
                                
                                st.info(f"""
                                **–ö–æ–Ω—Å–µ–Ω—Å—É—Å –º–æ–¥–µ–ª–µ–π:** {matching_models} –∏–∑ {total_models} –º–æ–¥–µ–ª–µ–π ({matching_models/total_models*100:.0f}%) 
                                –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –∫–ª–∞—Å—Å `{prediction}`.
                                
                                {'‚úÖ –í—ã—Å–æ–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–¥—ë–∂–Ω–æ' if matching_models/total_models > 0.7
                                 else '‚ö†Ô∏è –°—Ä–µ–¥–Ω—è—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å ‚Äî –º–æ–¥–µ–ª–∏ —Ä–∞—Å—Ö–æ–¥—è—Ç—Å—è –≤–æ –º–Ω–µ–Ω–∏—è—Ö' if matching_models/total_models > 0.5
                                 else '‚ùå –ù–∏–∑–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–º–Ω–∏—Ç–µ–ª–µ–Ω'}
                                """)
                    else:
                        # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        st.success(f"### üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ: **{prediction}**")
                        st.caption(f"–ú–æ–¥–µ–ª—å: {prediction_model_name}")
                        st.info("‚ö†Ô∏è –î–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—ã–≤–æ–¥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")